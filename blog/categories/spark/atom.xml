<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Spark | My Programmer's Road]]></title>
  <link href="http://ssledz.github.io/blog/categories/spark/atom.xml" rel="self"/>
  <link href="http://ssledz.github.io/"/>
  <updated>2017-08-25T11:16:07+02:00</updated>
  <id>http://ssledz.github.io/</id>
  <author>
    <name><![CDATA[Sławomir Śledź]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Simple Sbt Setup for Spark Project]]></title>
    <link href="http://ssledz.github.io/blog/2017/01/04/simple-sbt-setup-for-spark-project/"/>
    <updated>2017-01-04T18:03:14+01:00</updated>
    <id>http://ssledz.github.io/blog/2017/01/04/simple-sbt-setup-for-spark-project</id>
    <content type="html"><![CDATA[<p>Below can be found a simple sbt setup for a spark application in scala.</p>

<p>Directory layout</p>

<p>```
find .
.
./build.sbt
./src/main
./src/main/scala
./src/main/scala/pl
./src/main/scala/pl/softech
./src/main/scala/pl/softech/WordCountExample.scala
./src/main/resources
./src/main/resources/log4j.properties
./src/main/resources/words.txt</p>

<p>```</p>

<p>build.sbt
```
name := “spark-simple-app”</p>

<p>version := “1.0”</p>

<p>scalaVersion := “2.11.8”</p>

<p>val sparkVersion = “2.1.0”</p>

<p>libraryDependencies += “org.apache.spark” %% “spark-core” % sparkVersion
```</p>

<p>log4j.properties
<code>
log4j.rootCategory=ERROR, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
</code></p>

<p>WordCountExample.scala
```
package pl.softech</p>

<p>import org.apache.spark.{SparkConf, SparkContext}</p>

<p>object WordCountExample {</p>

<p>def main(args: Array[String]) {</p>

<pre><code>val conf = new SparkConf().setAppName("spark-simple-app").setMaster("local[*]")

val sc = new SparkContext(conf)

val textFile = sc.textFile("src/main/resources/words.txt")

val counts = textFile.flatMap(line =&gt; line.split(" "))
  .map(word =&gt; (word, 1))
  .reduceByKey(_ + _)
  .sortBy(-_._2)

printf(counts.collect().mkString("\n"))

sc.stop()   }
</code></pre>

<p>}
```</p>

<p>Sources can be found <a href="https://github.com/ssledz/ssledz.github.io-src/tree/master/spark-simple-template">here</a></p>
]]></content>
  </entry>
  
</feed>
